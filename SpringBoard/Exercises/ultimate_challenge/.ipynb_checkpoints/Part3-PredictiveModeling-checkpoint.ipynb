{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/jasonzhou/Documents/GitHub/Portfolio/SpringBoard/Exercises/ultimate_challenge\"\n",
    "os.chdir(path)\n",
    "\n",
    "df = pd.read_json(\"ultimate_data_challenge.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>trips_in_first_30_days</th>\n",
       "      <th>signup_date</th>\n",
       "      <th>avg_rating_of_driver</th>\n",
       "      <th>avg_surge</th>\n",
       "      <th>last_trip_date</th>\n",
       "      <th>phone</th>\n",
       "      <th>surge_pct</th>\n",
       "      <th>ultimate_black_user</th>\n",
       "      <th>weekday_pct</th>\n",
       "      <th>avg_dist</th>\n",
       "      <th>avg_rating_by_driver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>King's Landing</td>\n",
       "      <td>4</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>15.4</td>\n",
       "      <td>True</td>\n",
       "      <td>46.2</td>\n",
       "      <td>3.67</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-05-05</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>King's Landing</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2014-06-29</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>20.0</td>\n",
       "      <td>True</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Winterfell</td>\n",
       "      <td>14</td>\n",
       "      <td>2014-01-27</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.19</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>Android</td>\n",
       "      <td>11.8</td>\n",
       "      <td>False</td>\n",
       "      <td>82.4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>King's Landing</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-06-05</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.63</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-01-25</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Winterfell</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-31</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-05-22</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-01-15</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.58</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Astapor</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2014-04-20</td>\n",
       "      <td>Android</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 city  trips_in_first_30_days signup_date  \\\n",
       "0      King's Landing                       4  2014-01-25   \n",
       "1             Astapor                       0  2014-01-29   \n",
       "2             Astapor                       3  2014-01-06   \n",
       "3      King's Landing                       9  2014-01-10   \n",
       "4          Winterfell                      14  2014-01-27   \n",
       "...               ...                     ...         ...   \n",
       "49995  King's Landing                       0  2014-01-25   \n",
       "49996         Astapor                       1  2014-01-24   \n",
       "49997      Winterfell                       0  2014-01-31   \n",
       "49998         Astapor                       2  2014-01-14   \n",
       "49999         Astapor                       0  2014-01-18   \n",
       "\n",
       "       avg_rating_of_driver  avg_surge last_trip_date    phone  surge_pct  \\\n",
       "0                       4.7       1.10     2014-06-17   iPhone       15.4   \n",
       "1                       5.0       1.00     2014-05-05  Android        0.0   \n",
       "2                       4.3       1.00     2014-01-07   iPhone        0.0   \n",
       "3                       4.6       1.14     2014-06-29   iPhone       20.0   \n",
       "4                       4.4       1.19     2014-03-15  Android       11.8   \n",
       "...                     ...        ...            ...      ...        ...   \n",
       "49995                   5.0       1.00     2014-06-05   iPhone        0.0   \n",
       "49996                   NaN       1.00     2014-01-25   iPhone        0.0   \n",
       "49997                   5.0       1.00     2014-05-22  Android        0.0   \n",
       "49998                   3.0       1.00     2014-01-15   iPhone        0.0   \n",
       "49999                   NaN       1.00     2014-04-20  Android        0.0   \n",
       "\n",
       "       ultimate_black_user  weekday_pct  avg_dist  avg_rating_by_driver  \n",
       "0                     True         46.2      3.67                   5.0  \n",
       "1                    False         50.0      8.26                   5.0  \n",
       "2                    False        100.0      0.77                   5.0  \n",
       "3                     True         80.0      2.36                   4.9  \n",
       "4                    False         82.4      3.13                   4.9  \n",
       "...                    ...          ...       ...                   ...  \n",
       "49995                False        100.0      5.63                   4.2  \n",
       "49996                False          0.0      0.00                   4.0  \n",
       "49997                 True        100.0      3.86                   5.0  \n",
       "49998                False        100.0      4.58                   3.5  \n",
       "49999                False          0.0      3.49                   5.0  \n",
       "\n",
       "[50000 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   city                    50000 non-null  object \n",
      " 1   trips_in_first_30_days  50000 non-null  int64  \n",
      " 2   signup_date             50000 non-null  object \n",
      " 3   avg_rating_of_driver    41878 non-null  float64\n",
      " 4   avg_surge               50000 non-null  float64\n",
      " 5   last_trip_date          50000 non-null  object \n",
      " 6   phone                   49604 non-null  object \n",
      " 7   surge_pct               50000 non-null  float64\n",
      " 8   ultimate_black_user     50000 non-null  bool   \n",
      " 9   weekday_pct             50000 non-null  float64\n",
      " 10  avg_dist                50000 non-null  float64\n",
      " 11  avg_rating_by_driver    49799 non-null  float64\n",
      "dtypes: bool(1), float64(6), int64(1), object(4)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're just going to go ahead and fill null rating values with their respective means\n",
    "\n",
    "meanofrating = df['avg_rating_of_driver'].mean()\n",
    "meanbyrating = df['avg_rating_by_driver'].mean()\n",
    "\n",
    "df['avg_rating_of_driver'] = df['avg_rating_of_driver'].fillna(meanofrating)\n",
    "df['avg_rating_by_driver'] = df['avg_rating_by_driver'].fillna(meanbyrating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iPhone     34582\n",
       "Android    15022\n",
       "Name: phone, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what the current distribution of phone is between iPhones and Androids\n",
    "\n",
    "df['phone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that randomly returns \"Android\" or \"iPhone\" based on weighted probabilities\n",
    "\n",
    "import random\n",
    "\n",
    "def randomphone():\n",
    "    roll = random.random()\n",
    "    if roll > 0.7:\n",
    "        return \"Android\"\n",
    "    else:\n",
    "        return \"iPhone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems like the ratio is essentially 35/15, or 70/30 iPhones to Androids. We'll randomly fill in the missing phone\n",
    "# values according to these proportions\n",
    "\n",
    "df['phone'] = df['phone'].fillna(randomphone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   city                    50000 non-null  object \n",
      " 1   trips_in_first_30_days  50000 non-null  int64  \n",
      " 2   signup_date             50000 non-null  object \n",
      " 3   avg_rating_of_driver    50000 non-null  float64\n",
      " 4   avg_surge               50000 non-null  float64\n",
      " 5   last_trip_date          50000 non-null  object \n",
      " 6   phone                   50000 non-null  object \n",
      " 7   surge_pct               50000 non-null  float64\n",
      " 8   ultimate_black_user     50000 non-null  bool   \n",
      " 9   weekday_pct             50000 non-null  float64\n",
      " 10  avg_dist                50000 non-null  float64\n",
      " 11  avg_rating_by_driver    50000 non-null  float64\n",
      "dtypes: bool(1), float64(6), int64(1), object(4)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our focus of this project is to examine user retention, and two columns help with that: signup_date and \n",
    "# last_trip_date. We should create a new column that directly tells us the time difference between these two dates\n",
    "\n",
    "df['signup_date'][0][8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-18    2948\n",
       "2014-01-25    2885\n",
       "2014-01-11    2402\n",
       "2014-01-24    2284\n",
       "2014-01-17    2149\n",
       "2014-01-31    2100\n",
       "2014-01-19    2028\n",
       "2014-01-10    2021\n",
       "2014-01-06    1763\n",
       "2014-01-01    1737\n",
       "2014-01-26    1708\n",
       "2014-01-23    1606\n",
       "2014-01-07    1486\n",
       "2014-01-04    1485\n",
       "2014-01-30    1471\n",
       "2014-01-09    1433\n",
       "2014-01-16    1431\n",
       "2014-01-22    1369\n",
       "2014-01-05    1343\n",
       "2014-01-12    1334\n",
       "2014-01-20    1295\n",
       "2014-01-28    1284\n",
       "2014-01-08    1275\n",
       "2014-01-27    1236\n",
       "2014-01-21    1234\n",
       "2014-01-03    1213\n",
       "2014-01-29    1197\n",
       "2014-01-14    1120\n",
       "2014-01-15    1110\n",
       "2014-01-13    1049\n",
       "2014-01-02    1004\n",
       "Name: signup_date, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seeing the range of dates we have in the data\n",
    "\n",
    "df['signup_date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31425    2014-01-01\n",
       "10729    2014-01-01\n",
       "40336    2014-01-01\n",
       "34828    2014-01-01\n",
       "37295    2014-01-01\n",
       "            ...    \n",
       "45126    2014-07-01\n",
       "38651    2014-07-01\n",
       "14473    2014-07-01\n",
       "22735    2014-07-01\n",
       "45357    2014-07-01\n",
       "Name: last_trip_date, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['last_trip_date'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that determines difference in time between signup date and date of last trip. We're only really \n",
    "# interested in the month difference as a general measure\n",
    "\n",
    "def monthsApart(string1, string2):\n",
    "    year1 = int(string1[0:4])\n",
    "    month1 = int(string1[5:7])\n",
    "    day1 = int(string1[8:])\n",
    "    \n",
    "    year2 = int(string2[0:4])\n",
    "    month2 = int(string2[5:7])\n",
    "    day2 = int(string2[8:])\n",
    "    \n",
    "    date1 = datetime.datetime(year1, month1, day1)\n",
    "    date2 = datetime.datetime(year2, month2, day2)\n",
    "    \n",
    "    difference = date2 - date1\n",
    "    \n",
    "    return difference.months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daysApart(string1, string2):\n",
    "    year1 = int(string1[0:4])\n",
    "    month1 = int(string1[5:7])\n",
    "    day1 = int(string1[8:])\n",
    "    \n",
    "    year2 = int(string2[0:4])\n",
    "    month2 = int(string2[5:7])\n",
    "    day2 = int(string2[8:])\n",
    "    \n",
    "    date1 = datetime.datetime(year1, month1, day1)\n",
    "    date2 = datetime.datetime(year2, month2, day2)\n",
    "    \n",
    "    difference = date2 - date1\n",
    "    \n",
    "    return difference.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data set was collected up until July 1st, any users who booked a ride any time in June or exactly on July 1st would be considered an active user according to the provided definition of \"active user\". We'll define a function that determines this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isActive(string):\n",
    "    month = int(string[5:7])\n",
    "    if month >= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'datetime.timedelta' object has no attribute 'months'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-68b544f79c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmonthsretained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonthsApart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signup_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_trip_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdaysretained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaysApart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signup_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_trip_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0misactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misActive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last_trip_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-9a7f5ce0a4f2>\u001b[0m in \u001b[0;36mmonthsApart\u001b[0;34m(string1, string2)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdate1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdifference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'datetime.timedelta' object has no attribute 'months'"
     ]
    }
   ],
   "source": [
    "monthsretained = []\n",
    "daysretained = []\n",
    "isactive = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    monthsretained.append(monthsApart(df['signup_date'][i], df['last_trip_date'][i]))\n",
    "    daysretained.append(daysApart(df['signup_date'][i], df['last_trip_date'][i]))\n",
    "    isactive.append(isActive(df['last_trip_date'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['monthsretained'] = monthsretained\n",
    "df['daysretained'] = daysretained\n",
    "df['isActive'] = isactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubu = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['ultimate_black_user'][i]:\n",
    "        ubu.append(1)\n",
    "    else:\n",
    "        ubu.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ultimate_black_user'] = ubu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histograms\n",
    "\n",
    "_ = df.hist(column=['trips_in_first_30_days', 'avg_rating_of_driver', 'avg_surge',\n",
    "                    'surge_pct', 'weekday_pct', 'avg_dist', 'avg_rating_by_driver',\n",
    "                    'daysretained', 'isActive', 'ultimate_black_user'],\n",
    "            figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Most users have 12 or less trips in their first 30 days\n",
    "\n",
    "2) Most users score their drivers a 4 or 5\n",
    "\n",
    "3) Most users don't call for a trip if there's a surge going on\n",
    "\n",
    "4) Essentially the same column as 3)\n",
    "\n",
    "5) Many users only call for rides almost exclusively during the week or on weekends. \n",
    "\n",
    "6) Most users take shorter trips, with a few outliers skewing the shape of the graph\n",
    "\n",
    "7) Similarly to 2), most drivers score their passengers/users a 4 or 5. \n",
    "\n",
    "8) A large amount of users do not use the service for beyond 20 or so days. Interestingly enough, from there there are more users that use the service for a greater amount of time. Until the fall off at around 160 days.\n",
    "\n",
    "9) More users are \"inactive\" than active\n",
    "\n",
    "10) Most users did not take an Ultimate Black in their first 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting a separate histogram for monthsretained so we can assign an accurate binsize\n",
    "\n",
    "_ = df.hist(column='monthsretained', bins=7, figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 20% of users do not continue to use the service for more than a month, with around 35% of users using the service for 5 months. Very very few users use the service for exactly 6 months. \n",
    "\n",
    "We are interesting in determining our retention rate, which is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df[df['isActive'] == 1]) / len(df)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are to build a model that determines if a user will be active on their 6th month since signing up. Conveniently for us, we've already introduced an extra column that tracks this, 'monthsretained'. Based on this, we can assign a binary column that simply tells us if the user's 'monthsretained' is greater than equal to 6. From there we can model this problem as a classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having used the service on your 6th month means that you've used the service for 5 months\n",
    "\n",
    "active6 = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['monthsretained'][i] >= 5:\n",
    "        active6.append(1)\n",
    "    else:\n",
    "        active6.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['active6'] = active6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our non-numeric features are 'city', 'signup_date', 'last_trip_date', and 'phone'. 'city' and 'phone' are nominal data features, while the date features are ordinal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're going to factorize our non-numeric features so that we can look for any potential correlations there as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.unique(df['last_trip_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signupdatesF = []\n",
    "lasttripdatesF = []\n",
    "value1 = 0\n",
    "value2 = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    signupdate = df['signup_date'][i]\n",
    "    lasttripdate = df['last_trip_date'][i]\n",
    "    \n",
    "    for j in range(len(dates)):\n",
    "        if signupdate == dates[j]:\n",
    "            value1 = j + 1\n",
    "        if lasttripdate == dates[j]:\n",
    "            value2 = j + 1\n",
    "    \n",
    "    signupdatesF.append(value1)\n",
    "    lasttripdatesF.append(value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityF = pd.get_dummies(df['city'])\n",
    "phoneF = pd.get_dummies(df['phone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signupdatesF'] = signupdatesF\n",
    "df['lasttripdatesF'] = lasttripdatesF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEDA = pd.concat([df, pd.get_dummies(df['city'])], axis=1)\n",
    "dfEDA = pd.concat([dfEDA, pd.get_dummies(df['phone'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfEDA.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at features that correlate the most strongly with 'active6', we have 'trips_in_first_30_days', 'ultimate_black_user', 'weekday_pct', 'avg_dist', 'city', 'monthsretained', 'daysretained', and 'last_trip_date'. However we can't use any of 'monthsretained', 'daysretained', and 'last_trip_date' because 'active6' is derived from these columns. \n",
    "\n",
    "We'll the remaining features as our features of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = dfEDA[['trips_in_first_30_days', 'ultimate_black_user', 'weekday_pct', 'avg_dist', 'Astapor', 'King\\'s Landing']]\n",
    "\n",
    "y = df['active6']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import IndexLocator\n",
    "import itertools\n",
    "\n",
    "def plot_cm(y_test,y_pred_class,classes=['NON-default','DEFAULT']):\n",
    "    # plot confusion matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    cm = confusion_matrix(y_test, y_pred_class)\n",
    "    \n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    ax.set(yticks=[-0.5, 1.5], \n",
    "           xticks=[0, 1], \n",
    "           yticklabels=classes, \n",
    "           xticklabels=classes)\n",
    "    ax.yaxis.set_major_locator(IndexLocator(base=1, offset=0.5))\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cm(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(x): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "score = cv_score(clf, X_train, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the grid of parameters to search over\n",
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "\n",
    "# your turn\n",
    "\n",
    "scores = [0] * 5\n",
    "index = 0\n",
    "\n",
    "for cvalue in Cs:\n",
    "\n",
    "    clf = LogisticRegression(C=cvalue)\n",
    "    scores[index] = cv_score(clf, X_train, y_train)\n",
    "    index = index + 1\n",
    "\n",
    "\n",
    "print(scores)\n",
    "\n",
    "# It seems like 0.1, 1, and 100 are all tied with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_test, y_pred_class):\n",
    "    # Prints formatted classification metrics. \n",
    "    print('Classification Accuracy: ', format(accuracy_score(y_test, y_pred_class), '.3f'))\n",
    "    print('Precision score: ', format(precision_score(y_test, y_pred_class), '.3f'))\n",
    "    print('Recall score: ', format(recall_score(y_test, y_pred_class), '.3f'))\n",
    "    print('F1 score: ', format(f1_score(y_test, y_pred_class), '.3f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def logiRegr(X_train, y_train, X_test, y_test,**kwargs):\n",
    "    # Instantiate model. Use kwargs to pass parameters.\n",
    "    # Pass GridSearch best_params with ** to unpack.\n",
    "    logreg = LogisticRegression(random_state=1,**kwargs)\n",
    "    # Fit to training data.\n",
    "    logreg.fit(X_train, y_train)\n",
    "    # Examine coefficients\n",
    "    pprint.pprint(list(zip(X_train.columns,logreg.coef_[0])))\n",
    "    # Class predictions (not predicted probabilities)\n",
    "    y_pred_class = logreg.predict(X_test)\n",
    "    # Scoring metrics\n",
    "    scores(y_test, y_pred_class)\n",
    "    # Plot confusion matrix\n",
    "    plot_cm(y_test,y_pred_class)\n",
    "    \n",
    "def randomForest(X_train, y_train, X_test, y_test,**kwargs):\n",
    "    # Instantiate model. Use kwargs to pass parameters.\n",
    "    # Pass GridSearch best_params with ** to unpack.\n",
    "    rf = RandomForestClassifier(random_state=1, **kwargs) \n",
    "    # Fit to training data.\n",
    "    rf.fit(X_train,y_train)\n",
    "    # Class predictions\n",
    "    y_pred_class = rf.predict(X_test)\n",
    "    # Scoring metrics\n",
    "    scores(y_test, y_pred_class)\n",
    "    # Confusion matrix\n",
    "    plot_cm(y_test,y_pred_class)\n",
    "    \n",
    "def xgbClass(X_train, y_train, X_test, y_test,**kwargs):\n",
    "    # Instantiate model. Use kwargs to pass parameters.\n",
    "    # Pass GridSearch best_params with ** to unpack.\n",
    "    xg = xgb.XGBClassifier(seed=1,**kwargs)\n",
    "    # Fit to training data.\n",
    "    xg.fit(X_train,y_train)\n",
    "    # Class predictions\n",
    "    y_pred_class = xg.predict(X_test)\n",
    "    # Scoring metrics\n",
    "    scores(y_test, y_pred_class)\n",
    "    # Confusion matrix\n",
    "    plot_cm(y_test,y_pred_class)\n",
    "    \n",
    "def svmClass(X_train, y_train, X_test, y_test, **kwargs):\n",
    "    # Instantiate model. Use kwargs to pass parameters.\n",
    "    # Pass GridSearch best_params with ** to unpack.\n",
    "    svm = SVC(random_state=1,**kwargs)\n",
    "    # Fit to training data.\n",
    "    svm.fit(X_train, y_train)\n",
    "    # Class predictions\n",
    "    y_pred_class = svm.predict(X_test)\n",
    "    # Scoring metrics\n",
    "    scores(y_test, y_pred_class)\n",
    "    # Plot confusion matrix\n",
    "    plot_cm(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiRegr(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbClass(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
